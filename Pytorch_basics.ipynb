{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c41e3cee-cf47-4cec-ab04-10329d9b170a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.18.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.11.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed4e2e74-817b-487f-b329-06001763f811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0+cu118'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182f0ac-a0fe-4126-9627-2ec624c1d1dc",
   "metadata": {},
   "source": [
    "### Random tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6b3f1a2-6694-4079-a7f7-c84d57445a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2296, 0.3280, 0.0618, 0.8557],\n",
       "         [0.7230, 0.7865, 0.8799, 0.7952]],\n",
       "\n",
       "        [[0.0429, 0.5666, 0.3613, 0.3663],\n",
       "         [0.3151, 0.0687, 0.5716, 0.2701]],\n",
       "\n",
       "        [[0.0051, 0.2910, 0.4103, 0.0031],\n",
       "         [0.1917, 0.1666, 0.1884, 0.5061]],\n",
       "\n",
       "        [[0.7878, 0.5278, 0.4248, 0.4089],\n",
       "         [0.8555, 0.6624, 0.3909, 0.5735]],\n",
       "\n",
       "        [[0.6702, 0.4863, 0.6859, 0.2327],\n",
       "         [0.1327, 0.8980, 0.2449, 0.5892]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor=torch.rand(5,2,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f08e5ae-86db-427e-96c1-cf912fc33dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9562c9fd-f420-4d44-97c1-40b6b346698f",
   "metadata": {},
   "source": [
    "## random image tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aaaaabb-f594-431c-9f9e-3df32b7a62c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 113, 113]), 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_tensor=torch.rand(size= (3,113,113)) #Color channel,H,W\n",
    "random_image_tensor.shape,random_image_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fc82f1-1b39-424e-9417-75f9a1b884e8",
   "metadata": {},
   "source": [
    "## 0s and 1s tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d33c9d22-2e93-4048-8c44-24e93f356bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0s \n",
    "zeros=torch.zeros(2,3)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1c713b3-b784-4a52-8d13-acf34c42a689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1s\n",
    "ones=torch.ones(2,3)\n",
    "ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260127c8-f29f-4901-b30b-9deaeae8512c",
   "metadata": {},
   "source": [
    "### Creating a range and tensors like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb36ad06-8f47-464a-8726-07b3e40daa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range=torch.arange(1,11)\n",
    "range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aafcd7a1-d712-40ee-a300-2e44fec1dd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroes_like=torch.zeros_like(range)\n",
    "zeroes_like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0c6b87-8c31-4f16-b313-20f9b6e0d90d",
   "metadata": {},
   "source": [
    "# datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "353986c1-316b-4f9c-abe9-b96d37c8a57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e2ac0c3-7c0f-472d-befd-67e5510d8202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor=float_32_tensor.type(torch.float16) # can use tensor.half\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cda8a30-ddcb-40eb-9974-598be4c98a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor*float_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cead39a6-cc8b-42f1-8cda-f8e1ba859bb6",
   "metadata": {},
   "source": [
    "# Getting information from tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "276ca122-0651-4111-930c-477fbb239855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1018, 0.6948, 0.4201, 0.0618],\n",
      "        [0.7601, 0.9262, 0.4583, 0.3053],\n",
      "        [0.4915, 0.7142, 0.9622, 0.0436]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "\n",
    "# Find out details about it\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c2b589-1b06-454f-bc08-de19f060a5fe",
   "metadata": {},
   "source": [
    "# Manipulating tensors (tensor operations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e232c5b-7f21-4c86-ac69-3f3f409a93c0",
   "metadata": {},
   "source": [
    "These operations are often a wonderful dance between:\n",
    "\n",
    "1. Addition\n",
    "2. Substraction\n",
    "3. Multiplication (element-wise)\n",
    "4. Division\n",
    "5. Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a71528d-a341-4ac3-bb88-b0b92730e804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of values and add a number to it\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "771878b9-f50a-4b98-807d-1ce06a805521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply it by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80d9e688-7731-4bc5-8e3a-56218cce89d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensors don't change unless reassigned\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1848c5cc-2ab8-457d-aa74-b71e084457b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract and reassign\n",
    "tensor = tensor - 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbda7600-2332-467d-85c8-7ffbb6c92b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add and reassign\n",
    "tensor = tensor + 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3471d2a5-792f-401a-bd38-4f3c211deba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original tensor is still unchanged \n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9d7c2dd-0815-4d27-897e-c2aacdb0cbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication (each element multiplies its equivalent, index 0->0, 1->1, 2->2)\n",
    "print(tensor, \"*\", tensor)\n",
    "print(\"Equals:\", tensor * tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d6a842-aba7-4263-b028-0cd45f2916f2",
   "metadata": {},
   "source": [
    "# Matrix multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88d2e78e-9210-48e5-b710-4b60df5d08f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37d7feec-e133-4700-9639-3ec16efb60cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9f6175b-b27f-44c0-9a5a-21b1f6df9a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shapes need to be in the right way  \n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "\n",
    "tensor_A.shape, tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd078544-3f46-4733-a52d-ee683a186780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# View tensor_A and tensor_B.T\n",
    "print(tensor_A)\n",
    "print(tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d238eca-3cfb-4f36-a1e0-67989538d921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
      "\n",
      "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
      "\n",
      "Output:\n",
      "\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# The operation works when tensor_B is transposed\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
    "print(\"Output:\\n\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output) \n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a83a3-9eaa-4e8d-88f4-c05a561044d6",
   "metadata": {},
   "source": [
    "# Finding the min, max, mean, sum, etc (aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9dd6441-a6ec-4d19-9d87-b318ce28e640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "894f7a40-e668-42ba-91de-bc5173cd0a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: 0\n",
      "Maximum: 90\n",
      "Mean: 45.0\n",
      "Sum: 450\n"
     ]
    }
   ],
   "source": [
    "print(f\"Minimum: {x.min()}\")\n",
    "print(f\"Maximum: {x.max()}\")\n",
    "# print(f\"Mean: {x.mean()}\") # this will error\n",
    "print(f\"Mean: {x.type(torch.float32).mean()}\") # won't work without float datatype\n",
    "print(f\"Sum: {x.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaa83f2-22c0-4fc4-af75-c03bb905108b",
   "metadata": {},
   "source": [
    "# Positional min/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac25172f-8624-4500-8dfc-57ac514420e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Index where max value occurs: 9\n",
      "Index where min value occurs: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensor: {x}\")\n",
    "\n",
    "# Returns index of max and min values\n",
    "print(f\"Index where max value occurs: {x.argmax()}\")\n",
    "print(f\"Index where min value occurs: {x.argmin()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a4c52-23f2-4de1-be44-927fedb568b1",
   "metadata": {},
   "source": [
    "# Reshaping, stacking, squeezing and unsqueezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "653d9bf4-300f-46d2-a301-862e16b88550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "\n",
    "x = torch.arange(1., 8.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c10c4496-267b-4438-a594-dba3641181ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1, 7)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d959b2db-5652-43e9-8cfd-00064a03654b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change view (keeps same data as original but changes view)\n",
    "\n",
    "z = x.view(1, 7)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6048540b-b5c1-47d4-9600-1e2eb9c08776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0e62bf4-9f8a-417f-85c6-04a057e5ad8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x, x, x, x], dim=0) #dim=0\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5069aee-0d29-4482-9e61-1b47cc105d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5., 5.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x, x], dim=1) #dim=1\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd8027b-3dfe-490c-af15-ac9b65d5998c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
