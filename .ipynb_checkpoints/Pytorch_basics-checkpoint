{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7872a986-c25e-4d7d-bfb0-fcef1e8f2818",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (775891298.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c41e3cee-cf47-4cec-ab04-10329d9b170a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.18.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.11.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\acern\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed4e2e74-817b-487f-b329-06001763f811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0+cu118'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182f0ac-a0fe-4126-9627-2ec624c1d1dc",
   "metadata": {},
   "source": [
    "### Random tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6b3f1a2-6694-4079-a7f7-c84d57445a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0011, 0.7924, 0.5739, 0.1220],\n",
       "         [0.6557, 0.0270, 0.5870, 0.0462]],\n",
       "\n",
       "        [[0.8956, 0.0913, 0.1912, 0.2046],\n",
       "         [0.0570, 0.2301, 0.7955, 0.6335]],\n",
       "\n",
       "        [[0.8536, 0.1147, 0.5781, 0.2933],\n",
       "         [0.9843, 0.1626, 0.1137, 0.6604]],\n",
       "\n",
       "        [[0.9818, 0.3747, 0.9354, 0.9246],\n",
       "         [0.5009, 0.1172, 0.3273, 0.3366]],\n",
       "\n",
       "        [[0.5231, 0.7585, 0.8879, 0.6518],\n",
       "         [0.0881, 0.5263, 0.0640, 0.0339]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor=torch.rand(5,2,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f08e5ae-86db-427e-96c1-cf912fc33dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9562c9fd-f420-4d44-97c1-40b6b346698f",
   "metadata": {},
   "source": [
    "## random image tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aaaaabb-f594-431c-9f9e-3df32b7a62c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 113, 113]), 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_tensor=torch.rand(size= (3,113,113)) #Color channel,H,W\n",
    "random_image_tensor.shape,random_image_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fc82f1-1b39-424e-9417-75f9a1b884e8",
   "metadata": {},
   "source": [
    "## 0s and 1s tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d33c9d22-2e93-4048-8c44-24e93f356bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0s \n",
    "zeros=torch.zeros(2,3)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1c713b3-b784-4a52-8d13-acf34c42a689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1s\n",
    "ones=torch.ones(2,3)\n",
    "ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260127c8-f29f-4901-b30b-9deaeae8512c",
   "metadata": {},
   "source": [
    "### Creating a range and tensors like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb36ad06-8f47-464a-8726-07b3e40daa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range=torch.arange(1,11)\n",
    "range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aafcd7a1-d712-40ee-a300-2e44fec1dd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroes_like=torch.zeros_like(range)\n",
    "zeroes_like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0c6b87-8c31-4f16-b313-20f9b6e0d90d",
   "metadata": {},
   "source": [
    "# datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "353986c1-316b-4f9c-abe9-b96d37c8a57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e2ac0c3-7c0f-472d-befd-67e5510d8202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor=float_32_tensor.type(torch.float16) # can use tensor.half\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2cda8a30-ddcb-40eb-9974-598be4c98a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor*float_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cead39a6-cc8b-42f1-8cda-f8e1ba859bb6",
   "metadata": {},
   "source": [
    "# Getting information from tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "276ca122-0651-4111-930c-477fbb239855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9242, 0.0939, 0.9503, 0.8212],\n",
      "        [0.6100, 0.3328, 0.0660, 0.3128],\n",
      "        [0.6729, 0.6869, 0.2847, 0.9600]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "\n",
    "# Find out details about it\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c2b589-1b06-454f-bc08-de19f060a5fe",
   "metadata": {},
   "source": [
    "# Manipulating tensors (tensor operations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e232c5b-7f21-4c86-ac69-3f3f409a93c0",
   "metadata": {},
   "source": [
    "These operations are often a wonderful dance between:\n",
    "\n",
    "1. Addition\n",
    "2. Substraction\n",
    "3. Multiplication (element-wise)\n",
    "4. Division\n",
    "5. Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a71528d-a341-4ac3-bb88-b0b92730e804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of values and add a number to it\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "771878b9-f50a-4b98-807d-1ce06a805521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply it by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80d9e688-7731-4bc5-8e3a-56218cce89d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensors don't change unless reassigned\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1848c5cc-2ab8-457d-aa74-b71e084457b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract and reassign\n",
    "tensor = tensor - 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbda7600-2332-467d-85c8-7ffbb6c92b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add and reassign\n",
    "tensor = tensor + 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3471d2a5-792f-401a-bd38-4f3c211deba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original tensor is still unchanged \n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9d7c2dd-0815-4d27-897e-c2aacdb0cbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication (each element multiplies its equivalent, index 0->0, 1->1, 2->2)\n",
    "print(tensor, \"*\", tensor)\n",
    "print(\"Equals:\", tensor * tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d6a842-aba7-4263-b028-0cd45f2916f2",
   "metadata": {},
   "source": [
    "# Matrix multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88d2e78e-9210-48e5-b710-4b60df5d08f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37d7feec-e133-4700-9639-3ec16efb60cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f6175b-b27f-44c0-9a5a-21b1f6df9a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd078544-3f46-4733-a52d-ee683a186780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
